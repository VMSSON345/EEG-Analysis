{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab93cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess oddball (robust handling of events.tsv onset units)\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "BASE_DIR = r\"E:\\UNIVERSITY\\neurouScience\\btl-EEG\\data\\oddball_files\"\n",
    "SUBS = [f\"sub-{i:02d}\" for i in range(1, 11)]   \n",
    "OUT_DIR = os.path.join(BASE_DIR, \"preprocessed_mne\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Preproc params\n",
    "HP = 1.0\n",
    "LP = 40.0\n",
    "NOTCH = [50]\n",
    "SF_RESAMPLE = 250          # hoặc None để không resample\n",
    "EPOCH_TMIN, EPOCH_TMAX = -0.2, 0.8\n",
    "BASELINE = (EPOCH_TMIN, 0)\n",
    "REJECT = dict(eeg=150e-6)  # 150 µV threshold; set None để disable\n",
    "ICA_N_COMPONENTS = 0.95    # set None để skip ICA\n",
    "\n",
    "# Event mapping (use numeric codes found in your events file)\n",
    "# According to your events.json:\n",
    "# S  5 -> Standard (frequent)\n",
    "# S  6 -> Target\n",
    "# S  7 -> Deviant / Distractor\n",
    "EVENT_CODE_TO_NAME = {5: 'standard', 6: 'target', 7: 'distractor'}\n",
    "\n",
    "# Helper: parse event code like \"S  5\" -> 5\n",
    "def parse_event_code(s):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    m = re.search(r'(\\d+)', str(s))\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# Preprocess one subject\n",
    "def preprocess_subject(vhdr_path, events_tsv_path, out_dir=OUT_DIR):\n",
    "    sub = os.path.basename(vhdr_path).split('_')[0]  # e.g. sub-01\n",
    "    print(f\"--- Processing {sub} ---\")\n",
    "    raw = mne.io.read_raw_brainvision(vhdr_path, preload=True, verbose=False)\n",
    "    orig_sfreq = raw.info['sfreq']\n",
    "    duration_sec = raw.times[-1]\n",
    "    print(f\"sfreq={orig_sfreq} Hz, duration={duration_sec:.1f}s, nchan={raw.info['nchan']}\")\n",
    "\n",
    "    # Basic filters & ref\n",
    "    raw.notch_filter(NOTCH, picks='eeg', verbose=False)\n",
    "    raw.filter(HP, LP, picks='eeg', fir_design='firwin', verbose=False)\n",
    "    raw.set_eeg_reference('average', projection=False)\n",
    "    if SF_RESAMPLE is not None and SF_RESAMPLE < raw.info['sfreq']:\n",
    "        raw.resample(SF_RESAMPLE, npad='auto')\n",
    "\n",
    "    # Read events.tsv\n",
    "    ev = pd.read_csv(events_tsv_path, sep='\\t', dtype=str)\n",
    "    # Keep only stimulus trials (per your events.json)\n",
    "    if 'trial_type' in ev.columns:\n",
    "        ev = ev[ev['trial_type'].str.lower() == 'stimulus']\n",
    "    # parse event codes from event_type column\n",
    "    if 'event_type' in ev.columns:\n",
    "        ev['event_code'] = ev['event_type'].apply(parse_event_code)\n",
    "    else:\n",
    "        raise RuntimeError(\"events.tsv missing 'event_type' column\")\n",
    "\n",
    "    # parse onset column (may be 'seconds' per JSON, but values look like samples)\n",
    "    # Try convert to numeric\n",
    "    ev['onset_raw'] = pd.to_numeric(ev['onset'], errors='coerce')\n",
    "\n",
    "    # Decide whether onset is in samples or seconds:\n",
    "    # If maximum onset is much larger than recording duration (in seconds), it's likely samples.\n",
    "    max_onset = ev['onset_raw'].max()\n",
    "    sfreq = raw.info['sfreq']\n",
    "    if np.isnan(max_onset):\n",
    "        raise RuntimeError(\"No numeric onset values found in events.tsv\")\n",
    "\n",
    "    # Heuristic: if max_onset > duration_sec * 1.2  -> treat as samples\n",
    "    if max_onset > duration_sec * 1.2:\n",
    "        onset_in_samples = True\n",
    "    else:\n",
    "        onset_in_samples = False\n",
    "\n",
    "    if onset_in_samples:\n",
    "        print(\"Detected: onset values in EVENTS.TSV are in SAMPLES (converting to sample indices).\")\n",
    "        onset_samples = ev['onset_raw'].astype(int).values\n",
    "    else:\n",
    "        print(\"Detected: onset values in EVENTS.TSV are in SECONDS (converting to samples).\")\n",
    "        onset_samples = np.round(ev['onset_raw'].astype(float).values * sfreq).astype(int)\n",
    "\n",
    "    # build events array for MNE: (sample, 0, event_id)\n",
    "    event_codes = ev['event_code'].astype(int).values\n",
    "    events = np.column_stack((onset_samples, np.zeros_like(onset_samples, dtype=int), event_codes))\n",
    "\n",
    "    # Remove events falling outside raw sample range (safety)\n",
    "    good_mask = (events[:,0] >= 0) & (events[:,0] < raw.n_times)\n",
    "    if not np.all(good_mask):\n",
    "        nbad = np.sum(~good_mask)\n",
    "        print(f\"[WARN] {nbad} events outside recording bounds -> removed\")\n",
    "        events = events[good_mask]\n",
    "\n",
    "    # Build event_id mapping name -> int (for Epochs)\n",
    "    # Only include codes we care about (5,6,7)\n",
    "    event_id = {}\n",
    "    for code, name in EVENT_CODE_TO_NAME.items():\n",
    "        # find if code present in events\n",
    "        if code in events[:,2]:\n",
    "            event_id[name] = code\n",
    "\n",
    "    if len(event_id) == 0:\n",
    "        raise RuntimeError(\"No valid stimulus event codes (5/6/7) found in events.tsv / events array.\")\n",
    "\n",
    "    # Epoching: allow duplicate event times (event_repeated='merge')\n",
    "    epochs = mne.Epochs(raw, events, event_id=event_id,\n",
    "                        tmin=EPOCH_TMIN, tmax=EPOCH_TMAX,\n",
    "                        baseline=BASELINE, preload=True,\n",
    "                        event_repeated='merge', verbose=False)\n",
    "\n",
    "    # Reject bad epochs (optional)\n",
    "    if REJECT is not None:\n",
    "        try:\n",
    "            epochs.drop_bad(reject=REJECT)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] drop_bad failed: {e}\")\n",
    "\n",
    "    # ICA (optional) - try to remove EOG if available\n",
    "    if ICA_N_COMPONENTS is not None:\n",
    "        try:\n",
    "            ica = mne.preprocessing.ICA(n_components=ICA_N_COMPONENTS, random_state=97, max_iter='auto')\n",
    "            # fit on raw (filtered)\n",
    "            ica.fit(raw.copy().filter(1., 40., picks='eeg'), picks='eeg')\n",
    "            # try to find eog channels or frontal channels\n",
    "            eog_chs = mne.pick_types(raw.info, eeg=False, eog=True)\n",
    "            if len(eog_chs) > 0:\n",
    "                ch_names = [raw.ch_names[i] for i in eog_chs]\n",
    "                eog_inds, scores = ica.find_bads_eog(raw, ch_name=ch_names)\n",
    "                ica.exclude = list(set(ica.exclude).union(set(eog_inds)))\n",
    "            else:\n",
    "                frontal = [ch for ch in ['Fp1','Fp2','Fpz'] if ch in raw.ch_names]\n",
    "                if frontal:\n",
    "                    eog_inds, scores = ica.find_bads_eog(raw, ch_name=frontal)\n",
    "                    ica.exclude = list(set(ica.exclude).union(set(eog_inds)))\n",
    "            # apply to epochs\n",
    "            ica.apply(epochs)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] ICA failed or skipped: {e}\")\n",
    "\n",
    "    # compute evokeds\n",
    "    evokeds = {cond: epochs[cond].average() for cond in epochs.event_id}\n",
    "\n",
    "    # Save outputs\n",
    "    subj_out = os.path.join(out_dir, os.path.basename(vhdr_path).split('_')[0])\n",
    "    os.makedirs(subj_out, exist_ok=True)\n",
    "    raw_out = os.path.join(subj_out, f\"{os.path.basename(vhdr_path).split('.')[0]}_preproc_raw.fif\")\n",
    "    epochs_out = os.path.join(subj_out, f\"{os.path.basename(vhdr_path).split('.')[0]}_preproc-epo.fif\")\n",
    "    epochs.save(epochs_out, overwrite=True)\n",
    "    raw.save(raw_out, overwrite=True)\n",
    "\n",
    "    # Save a small summary CSV\n",
    "    summary = {\n",
    "        'subject': os.path.basename(vhdr_path).split('_')[0],\n",
    "        'n_channels': raw.info['nchan'],\n",
    "        'orig_sfreq': orig_sfreq,\n",
    "        'processed_sfreq': raw.info['sfreq'],\n",
    "        'n_epochs_total': len(epochs),\n",
    "        'event_id_keys': list(event_id.keys())\n",
    "    }\n",
    "    pd.DataFrame([summary]).to_csv(os.path.join(subj_out, 'preproc_summary.csv'), index=False)\n",
    "\n",
    "    print(f\"[OK] {sub} done. Saved epochs -> {epochs_out}\")\n",
    "    return summary\n",
    "\n",
    "# ========== Run for all subs found ==========\n",
    "results = []\n",
    "for sub in SUBS:\n",
    "    vhdr = os.path.join(BASE_DIR, f\"{sub}_task-oddball_eeg.vhdr\")\n",
    "    tsv = os.path.join(BASE_DIR, f\"{sub}_task-oddball_events.tsv\")\n",
    "    if not os.path.exists(vhdr):\n",
    "        print(f\"[SKIP] {sub}: vhdr not found at {vhdr}\")\n",
    "        continue\n",
    "    if not os.path.exists(tsv):\n",
    "        print(f\"[SKIP] {sub}: events.tsv not found at {tsv}\")\n",
    "        continue\n",
    "    try:\n",
    "        res = preprocess_subject(vhdr, tsv)\n",
    "        results.append(res)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {sub}: {e}\")\n",
    "\n",
    "# Save overall log\n",
    "pd.DataFrame(results).to_csv(os.path.join(OUT_DIR, \"all_subjects_preproc_log.csv\"), index=False)\n",
    "print(\"All done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
